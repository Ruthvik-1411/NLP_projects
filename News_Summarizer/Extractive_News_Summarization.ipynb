{"cells":[{"cell_type":"markdown","metadata":{"id":"ESSY43RIlGIw"},"source":["## Extractive Text Summarization\n","This notebook peforms an end to end solution to perform extractive text summarization on CNN dailymail dataset."]},{"cell_type":"markdown","source":["## Model Building and Testing"],"metadata":{"id":"iO97VXXtriJl"}},{"cell_type":"markdown","source":["### Importing Libraries\n","We first install required packages in the colab environment to train the model.\n","We then import all the packages and modules for later use."],"metadata":{"id":"8crO3WALrp2u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HY5BXTZGfEB8"},"outputs":[],"source":["!pip install transformers datasets -q\n","import time\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from datasets import load_dataset, load_metric"]},{"cell_type":"markdown","metadata":{"id":"V4Jw97rBlGI6"},"source":["### Downloading Dataset\n","\n","*   We first load the cnn_dailmail dataset\n","*   Contents of the news_dataset:\n","  *  Article - The text part of the article\n","  *  Highlights - The summary of the article\n","  *  Id - unique id for the article (hash value)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-z-HvAKvreWa"},"outputs":[],"source":["news_datasets = load_dataset(\"cnn_dailymail\",'3.0.0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbqGnwixr2pc"},"outputs":[],"source":["# Since the data is huge (training - 287113 articles) we take only small percentage\n","# Define the percentages for train, validation, and test splits\n","train_percent = 1\n","validation_percent = 1\n","test_percent = 1\n","\n","# Calculate the number of examples for each split\n","train_len = len(news_datasets[\"train\"])\n","val_len = len(news_datasets[\"validation\"])\n","test_len = len(news_datasets[\"test\"])\n","train_split = train_len * train_percent // 100\n","validation_split = val_len * validation_percent // 100\n","test_split = test_len * test_percent // 100\n","\n","# Create new datasets with the desired splits\n","train_dataset = news_datasets[\"train\"].shuffle(seed=42).select([i for i in range(train_split)])\n","validation_dataset = news_datasets[\"validation\"].shuffle(seed=42).select([i for i in range(validation_split)])\n","test_dataset = news_datasets[\"test\"].shuffle(seed=42).select([i for i in range(test_split)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q43GAAldsxBg","colab":{"base_uri":"https://localhost:8080/","height":140},"outputId":"300fb86a-14ea-4be5-a828-650770d81e88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"By . Anthony Bond . PUBLISHED: . 07:03 EST, 2 March 2013 . | . UPDATED: . 08:07 EST, 2 March 2013 . Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide poisoning from a cooker. Tragic: The inquests have opened into the deaths of three members of the same family who were found in their static caravan last weekend. John and Audrey Cook are pictured . Awful: The family died following carbon monoxide poisoning at this caravan at the Tremarle Home Park in Camborne, Cornwall . It is also believed there was no working carbon monoxide detector in the static caravan. Cornwall Fire and Rescue Service said this would have resulted in the three being unconscious 'within minutes', . A spokesman for Cornwall coroner Dr Emma Carlyon confirmed the inquests were opened and adjourned yesterday afternoon. They will resume at a later date. Devon and Cornwall Police confirmed on Monday that carbon monoxide poisoning had been established as the cause of death. A police spokesman said the source of the poisoning was 'believed to be from incorrect operation of the gas cooker'. Poisoning: This woman left flowers outside the caravan following the deaths. It has emerged that the trio would have been unconscious 'within minutes' Touching: This tribute was left outside the caravan following news of the deaths . Early readings from experts at the site revealed a potentially lethal level of carbon monoxide present within the caravan at the time it was taken, shortly after the discovery of the bodies. Friends and neighbours have paid tribute to the trio. One . neighbour, Sonya Owen, 53, said: 'It's very distressing. I knew the . daughter, she was living her with her mum and dad. Everybody is really . upset.' Margaret Holmes, 65, who lived near the couple and their . daughter, said: 'They had lived here for around 40 years and they kept . themselves to themselves. 'I just can’t believe this has . happened, it is so sad and I am so shocked, I think we all are, you just . don’t expect this sort of thing to happen on your doorstep. 'Everyone will miss them, we used to chat a lot when we were both in the garden. 'I would just like to send my condolences to their family, I can’t imagine what they’re going through.' Nic Clark, 52, who was good friends with daughter Maureen, added: 'They were a lovely kind family, a great trio. 'Maureen . used to go out and walk her dog, a little Jack Russell, it is so sad . what has happened, I understand the dog went with them. 'They . will be sorely missed and I think everyone is just in shock at the . moment, I would like to send my condolences to the Cook family.'\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["train_dataset[0]['article']"]},{"cell_type":"code","source":["len(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rq3MGJ_Rud14","outputId":"eade5533-8f72-472c-a968-0ece4d6988e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2871"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"CV25YO8dlGJE"},"source":["### Tokenizing\n","* We first define the pre-defined model we want use, here it is bert.\n","* We initialize a tokenizer using the pre-trained model specified. The BertTokenizer.from_pretrained method loads the tokenizer corresponding to bert-based-uncased model.\n","* The tokenizer is used to preprocess and tokenize text data, making it suitable for input to our model. It converts text to tokens, padding sequences, and converts tokens back to text.\n","* So in a way tokenizer is also a part of pre-processing before the model receives it. The articles are passed throught this and then to the model.\n","* We initialize a function to tokenize data that takes the reduced data from train, validation and test data and applied this tokenizer on each article, highlights in the data. It generated input_ids, attention mask and labels.\n","* It compares if the sentence is in the summary and if there it assigns a 1 else 0.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quv7cdhROiiF"},"outputs":[],"source":["# Initialize the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Tokenize the data\n","def tokenize_data(data, max_length):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","\n","    for each in range(len(data)):\n","        text = data[each]['article']\n","        label = data[each]['highlights']\n","\n","        sentences = text.split(\".\")\n","\n","        # Tokenize each sentence\n","        encoded_sentences = tokenizer(sentences, padding=\"max_length\", truncation=True, return_tensors=\"tf\", max_length=max_length)\n","        input_ids.extend(encoded_sentences[\"input_ids\"])\n","        attention_masks.extend(encoded_sentences[\"attention_mask\"])\n","\n","        # Determine which sentences are important and create binary labels (0 for not important, 1 for important)\n","        sentence_importance = [1 if sentence in label else 0 for sentence in text.split(\".\")]\n","\n","        labels.extend(sentence_importance)\n","\n","    return input_ids, attention_masks, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Js2dB2s9VkhH"},"outputs":[],"source":["# Defining hyperparameters\n","max_length = 256\n","batch_size = 4"]},{"cell_type":"markdown","metadata":{"id":"neK9TzcLlGJK"},"source":["#### Preprocessing the data by passing through tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aO0zQ3P1lGJL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c224a58-b56d-44c4-e757-ff7f4238b3b9"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["# Tokenizing the datasets\n","train_input_ids, train_attention_masks, train_labels = tokenize_data(train_dataset, max_length)\n","validation_input_ids, validation_attention_masks, validation_labels = tokenize_data(validation_dataset, max_length)\n","test_input_ids, test_attention_masks, test_labels = tokenize_data(test_dataset, max_length)"]},{"cell_type":"markdown","metadata":{"id":"FxaQiGL2lGJM"},"source":["### Converting to Tf dataset\n","* We convert the tokenized datasets into tf dataset format that is compatible with the model.\n","* TensorFlow datasets allow for efficient and batched data processing, making it easier to train deep learning models on large datasets.\n","* We can now use these datasets with the model to train and evaluate text summarization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOBD8UIYlGJN"},"outputs":[],"source":["train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_input_ids, train_attention_masks, train_labels))\n","validation_dataset_tf = tf.data.Dataset.from_tensor_slices((validation_input_ids, validation_attention_masks, validation_labels))\n","test_dataset_tf = tf.data.Dataset.from_tensor_slices((test_input_ids, test_attention_masks, test_labels))"]},{"cell_type":"markdown","metadata":{"id":"CxADq8c6lGJO"},"source":["#### We can shuffle the data and divide the input into batches for training and inference."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wfh5NVVXlGJP"},"outputs":[],"source":["train_dataset_tf = train_dataset_tf.batch(batch_size).shuffle(buffer_size=100)\n","validation_dataset_tf = validation_dataset_tf.batch(batch_size)\n","test_dataset_tf = test_dataset_tf.batch(batch_size)"]},{"cell_type":"markdown","metadata":{"id":"c3TitSiAlGJP"},"source":["### Fine Tuning the Model\n","* We initialize a BERT model for sequence classification.\n","* TFBertForSequenceClassification.from_pretrained is designed for sequence classification tasks, where the model takes a sequence of tokens as input and predicts a category or label for that sequence.\n","* Since we classified the sentences as 0 or 1 we give num_labels as 2."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["d2a46f7007494eb88cc01eeebfc6d683","a08dffc17cf54132b4e2c5fcab05b7f9","5d2e7a414dcd4e29b563f15d4fc8312e","a25399bd0c4849d7aabb4411cf21569e","3a152bf1916b4baaa9571646025744e6","b09f4cfcc5df48e8b2884b888c1cf6e3","5e1ba5f11fa24dbd8271d851564374da","444877b0dfc74a2d99c1fd385080bc93","e849f91bdc424fa8ab21de66e6f30778","c9186d11502448aabb12eaabab99445b","d38313cb1cb04dacbc7d1330bb0d4fe3"]},"id":"LimfNzIzqejz","outputId":"43008eed-6e66-4b93-c891-8b158880402d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a46f7007494eb88cc01eeebfc6d683"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"]},{"cell_type":"markdown","metadata":{"id":"Rp4G6wjLlGJQ"},"source":["### Training the model\n","* We initiliaze the optimizer for the model and loss function\n","* We define the hyperparameters for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STX0mcpFrFHC"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRCTutldlGJS"},"outputs":[],"source":["accumulation_steps = 4  # Accumulate gradients every 4 steps\n","step = 0  # Initialize the step counter\n","num_epochs = 1"]},{"cell_type":"markdown","metadata":{"id":"C-u9HWtKlGJS"},"source":["#### Training the model over train_dataset\n","* We go over each article that is tokenized in terms of batches.\n","* with tf.GradientTape() as tape - This is used for calculating gradients and it allows tensorFlow to keep track of operations for gradient computation.\n","* We get the output from the model containing the raw scores for the task.\n","* The logits are then compared against the ground truth (labels). We accumulate the gradient over the steps so that we can perform in batches.\n","* The gradients are then applied to update the weights with the optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQ2Wd9Z1lGJS","outputId":"fe351ea3-7145-4ce2-a622-fca53fc0220b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7c4d04689bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7c4d04689bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/1] - Step [4/30732] - Loss: 0.15715251863002777\n","Epoch [1/1] - Step [8/30732] - Loss: 0.10688062012195587\n","Epoch [1/1] - Step [12/30732] - Loss: 0.1459098756313324\n","Epoch [1/1] - Step [16/30732] - Loss: 0.06755093485116959\n","Epoch [1/1] - Step [20/30732] - Loss: 0.14754396677017212\n","Epoch [1/1] - Step [24/30732] - Loss: 0.12900492548942566\n","Epoch [1/1] - Step [28/30732] - Loss: 0.019558699801564217\n","Epoch [1/1] - Step [32/30732] - Loss: 0.017782138660550117\n","Epoch [1/1] - Step [36/30732] - Loss: 0.01188712939620018\n","Epoch [1/1] - Step [40/30732] - Loss: 0.08939484506845474\n","Epoch [1/1] - Step [44/30732] - Loss: 0.05446353554725647\n","Epoch [1/1] - Step [48/30732] - Loss: 0.0070655024610459805\n","Epoch [1/1] - Step [52/30732] - Loss: 0.0792413130402565\n","Epoch [1/1] - Step [56/30732] - Loss: 0.006066455505788326\n","Epoch [1/1] - Step [60/30732] - Loss: 0.005495986435562372\n","Epoch [1/1] - Step [64/30732] - Loss: 0.004540382884442806\n","Epoch [1/1] - Step [68/30732] - Loss: 0.003574148751795292\n","Epoch [1/1] - Step [72/30732] - Loss: 0.22319626808166504\n","Epoch [1/1] - Step [76/30732] - Loss: 0.0053811147809028625\n","Epoch [1/1] - Step [80/30732] - Loss: 0.028916342183947563\n","Epoch [1/1] - Step [84/30732] - Loss: 0.01589711755514145\n","Epoch [1/1] - Step [88/30732] - Loss: 0.0030981400050222874\n","Epoch [1/1] - Step [92/30732] - Loss: 0.0028702544514089823\n","Epoch [1/1] - Step [96/30732] - Loss: 0.004318688064813614\n","Epoch [1/1] - Step [100/30732] - Loss: 0.0022624938283115625\n","Epoch [1/1] - Step [104/30732] - Loss: 0.0022088242694735527\n","Epoch [1/1] - Step [108/30732] - Loss: 0.03070245124399662\n","Epoch [1/1] - Step [112/30732] - Loss: 0.0023939330130815506\n","Epoch [1/1] - Step [116/30732] - Loss: 0.0018218737095594406\n","Epoch [1/1] - Step [120/30732] - Loss: 0.009291552007198334\n","Epoch [1/1] - Step [124/30732] - Loss: 0.00165508221834898\n","Epoch [1/1] - Step [128/30732] - Loss: 0.0017985794693231583\n","Epoch [1/1] - Step [132/30732] - Loss: 0.005725610535591841\n","Epoch [1/1] - Step [136/30732] - Loss: 0.1708700805902481\n","Epoch [1/1] - Step [140/30732] - Loss: 0.0035809502005577087\n","Epoch [1/1] - Step [144/30732] - Loss: 0.0018469312926754355\n","Epoch [1/1] - Step [148/30732] - Loss: 0.0014115736121311784\n","Epoch [1/1] - Step [152/30732] - Loss: 0.15307629108428955\n","Epoch [1/1] - Step [156/30732] - Loss: 0.0015199208864942193\n","Epoch [1/1] - Step [160/30732] - Loss: 0.09331808984279633\n","Epoch [1/1] - Step [164/30732] - Loss: 0.0013532810844480991\n","Epoch [1/1] - Step [168/30732] - Loss: 0.0014616569969803095\n","Epoch [1/1] - Step [172/30732] - Loss: 0.0013635761570185423\n","Epoch [1/1] - Step [176/30732] - Loss: 0.01664687506854534\n","Epoch [1/1] - Step [180/30732] - Loss: 0.0025885007344186306\n","Epoch [1/1] - Step [184/30732] - Loss: 0.0015415543457493186\n","Epoch [1/1] - Step [188/30732] - Loss: 0.022979650646448135\n","Epoch [1/1] - Step [192/30732] - Loss: 0.027159247547388077\n","Epoch [1/1] - Step [196/30732] - Loss: 0.021530847996473312\n","Epoch [1/1] - Step [200/30732] - Loss: 0.0011296605225652456\n","Epoch [1/1] - Step [204/30732] - Loss: 0.000967519183177501\n","Epoch [1/1] - Step [208/30732] - Loss: 0.0012603974901139736\n","Epoch [1/1] - Step [212/30732] - Loss: 0.0008309351978823543\n","Epoch [1/1] - Step [216/30732] - Loss: 0.005428621079772711\n","Epoch [1/1] - Step [220/30732] - Loss: 0.0006421568687073886\n","Epoch [1/1] - Step [224/30732] - Loss: 0.0007688776240684092\n","Epoch [1/1] - Step [228/30732] - Loss: 0.0006073939730413258\n","Epoch [1/1] - Step [232/30732] - Loss: 0.0006770583568140864\n","Epoch [1/1] - Step [236/30732] - Loss: 0.000815599865745753\n","Epoch [1/1] - Step [240/30732] - Loss: 0.016006160527467728\n","Epoch [1/1] - Step [244/30732] - Loss: 0.0035990034230053425\n","Epoch [1/1] - Step [248/30732] - Loss: 0.0005866553401574492\n","Epoch [1/1] - Step [252/30732] - Loss: 0.0017425748519599438\n","Epoch [1/1] - Step [256/30732] - Loss: 0.0007363380864262581\n","Epoch [1/1] - Step [260/30732] - Loss: 0.0004996636416763067\n","Epoch [1/1] - Step [264/30732] - Loss: 0.0005365773686207831\n","Epoch [1/1] - Step [268/30732] - Loss: 0.0005429279408417642\n","Epoch [1/1] - Step [272/30732] - Loss: 0.00046571623533964157\n","Epoch [1/1] - Step [276/30732] - Loss: 0.0037110724952071905\n","Epoch [1/1] - Step [280/30732] - Loss: 0.0005258709425106645\n","Epoch [1/1] - Step [284/30732] - Loss: 0.0007143981638364494\n","Epoch [1/1] - Step [288/30732] - Loss: 0.00043337620445527136\n","Epoch [1/1] - Step [292/30732] - Loss: 0.0005019398522563279\n","Epoch [1/1] - Step [296/30732] - Loss: 0.0023208612110465765\n","Epoch [1/1] - Step [300/30732] - Loss: 0.3327707350254059\n","Epoch [1/1] - Step [304/30732] - Loss: 0.0023153917863965034\n","Epoch [1/1] - Step [308/30732] - Loss: 0.002193544525653124\n","Epoch [1/1] - Step [312/30732] - Loss: 0.003187374444678426\n","Epoch [1/1] - Step [316/30732] - Loss: 0.005762224551290274\n","Epoch [1/1] - Step [320/30732] - Loss: 0.013140739873051643\n","Epoch [1/1] - Step [324/30732] - Loss: 0.015990495681762695\n","Epoch [1/1] - Step [328/30732] - Loss: 0.0006507131038233638\n","Epoch [1/1] - Step [332/30732] - Loss: 0.0006311195902526379\n","Epoch [1/1] - Step [336/30732] - Loss: 0.0004788723308593035\n","Epoch [1/1] - Step [340/30732] - Loss: 0.0005212603718973696\n","Epoch [1/1] - Step [344/30732] - Loss: 0.0018500039586797357\n","Epoch [1/1] - Step [348/30732] - Loss: 0.00136078882496804\n","Epoch [1/1] - Step [352/30732] - Loss: 0.006534895393997431\n","Epoch [1/1] - Step [356/30732] - Loss: 0.07983135432004929\n","Epoch [1/1] - Step [360/30732] - Loss: 0.009128413163125515\n","Epoch [1/1] - Step [364/30732] - Loss: 0.00817192904651165\n","Epoch [1/1] - Step [368/30732] - Loss: 0.006339550483971834\n","Epoch [1/1] - Step [372/30732] - Loss: 0.007768073584884405\n","Epoch [1/1] - Step [376/30732] - Loss: 0.011902661062777042\n","Epoch [1/1] - Step [380/30732] - Loss: 0.04601199924945831\n","Epoch [1/1] - Step [384/30732] - Loss: 0.0007681404240429401\n","Epoch [1/1] - Step [388/30732] - Loss: 0.0011610445799306035\n","Epoch [1/1] - Step [392/30732] - Loss: 0.004146093502640724\n","Epoch [1/1] - Step [396/30732] - Loss: 0.006191090680658817\n","Epoch [1/1] - Step [400/30732] - Loss: 0.025480397045612335\n","Epoch [1/1] - Step [404/30732] - Loss: 0.031287774443626404\n","Epoch [1/1] - Step [408/30732] - Loss: 0.009296488016843796\n","Epoch [1/1] - Step [412/30732] - Loss: 0.0013747491175308824\n","Epoch [1/1] - Step [416/30732] - Loss: 0.025674810633063316\n","Epoch [1/1] - Step [420/30732] - Loss: 0.0010116270277649164\n","Epoch [1/1] - Step [424/30732] - Loss: 0.0014160824939608574\n","Epoch [1/1] - Step [428/30732] - Loss: 0.001179825863800943\n","Epoch [1/1] - Step [432/30732] - Loss: 0.0006286898860707879\n","Epoch [1/1] - Step [436/30732] - Loss: 0.001360661000944674\n","Epoch [1/1] - Step [440/30732] - Loss: 0.0006655583274550736\n","Epoch [1/1] - Step [444/30732] - Loss: 0.0005703696515411139\n","Epoch [1/1] - Step [448/30732] - Loss: 0.0006186477839946747\n","Epoch [1/1] - Step [452/30732] - Loss: 0.0005178619758225977\n","Epoch [1/1] - Step [456/30732] - Loss: 0.00043881521560251713\n","Epoch [1/1] - Step [460/30732] - Loss: 0.0006194969173520803\n","Epoch [1/1] - Step [464/30732] - Loss: 0.0012475179973989725\n","Epoch [1/1] - Step [468/30732] - Loss: 0.003952201921492815\n","Epoch [1/1] - Step [472/30732] - Loss: 0.0024007305037230253\n","Epoch [1/1] - Step [476/30732] - Loss: 0.0011210078373551369\n","Epoch [1/1] - Step [480/30732] - Loss: 0.0013064976083114743\n","Epoch [1/1] - Step [484/30732] - Loss: 0.0008953459328040481\n","Epoch [1/1] - Step [488/30732] - Loss: 0.000839382060803473\n","Epoch [1/1] - Step [492/30732] - Loss: 0.0009911807719618082\n","Epoch [1/1] - Step [496/30732] - Loss: 0.0008259890018962324\n","Epoch [1/1] - Step [500/30732] - Loss: 0.004521316848695278\n","Epoch [1/1] - Step [504/30732] - Loss: 0.0005906508304178715\n","Epoch [1/1] - Step [508/30732] - Loss: 0.0004842777270823717\n","Epoch [1/1] - Step [512/30732] - Loss: 0.0011384862009435892\n","Epoch [1/1] - Step [516/30732] - Loss: 0.001197120058350265\n","Epoch [1/1] - Step [520/30732] - Loss: 0.0011215123813599348\n","Epoch [1/1] - Step [524/30732] - Loss: 0.0015282967360690236\n","Epoch [1/1] - Step [528/30732] - Loss: 0.004501035902649164\n","Epoch [1/1] - Step [532/30732] - Loss: 0.008530736900866032\n","Epoch [1/1] - Step [536/30732] - Loss: 0.0020524209830909967\n","Epoch [1/1] - Step [540/30732] - Loss: 0.001588431652635336\n","Epoch [1/1] - Step [544/30732] - Loss: 0.0009634781745262444\n","Epoch [1/1] - Step [548/30732] - Loss: 0.0008531229686923325\n","Epoch [1/1] - Step [552/30732] - Loss: 0.0009690818842500448\n","Epoch [1/1] - Step [556/30732] - Loss: 0.0009073428809642792\n","Epoch [1/1] - Step [560/30732] - Loss: 0.0006703166873194277\n","Epoch [1/1] - Step [564/30732] - Loss: 0.0007924837991595268\n","Epoch [1/1] - Step [568/30732] - Loss: 0.0007733078673481941\n","Epoch [1/1] - Step [572/30732] - Loss: 0.008093757554888725\n","Epoch [1/1] - Step [576/30732] - Loss: 0.0007928500417619944\n","Epoch [1/1] - Step [580/30732] - Loss: 0.000791098631452769\n","Epoch [1/1] - Step [584/30732] - Loss: 0.06445786356925964\n","Epoch [1/1] - Step [588/30732] - Loss: 0.004082273691892624\n","Epoch [1/1] - Step [592/30732] - Loss: 0.02739778906106949\n","Epoch [1/1] - Step [596/30732] - Loss: 0.001598909730091691\n","Epoch [1/1] - Step [600/30732] - Loss: 0.0007232212228700519\n","Epoch [1/1] - Step [604/30732] - Loss: 0.004865438677370548\n","Epoch [1/1] - Step [608/30732] - Loss: 0.003249924397096038\n","Epoch [1/1] - Step [612/30732] - Loss: 0.000811450183391571\n","Epoch [1/1] - Step [616/30732] - Loss: 0.00299282930791378\n","Epoch [1/1] - Step [620/30732] - Loss: 0.004413460846990347\n","Epoch [1/1] - Step [624/30732] - Loss: 0.0005337754264473915\n","Epoch [1/1] - Step [628/30732] - Loss: 0.07350095361471176\n","Epoch [1/1] - Step [632/30732] - Loss: 0.027079660445451736\n","Epoch [1/1] - Step [636/30732] - Loss: 0.0007669322658330202\n","Epoch [1/1] - Step [640/30732] - Loss: 0.004017360508441925\n","Epoch [1/1] - Step [644/30732] - Loss: 0.00044206701568327844\n","Epoch [1/1] - Step [648/30732] - Loss: 0.00043018735595978796\n","Epoch [1/1] - Step [652/30732] - Loss: 0.0010021802736446261\n","Epoch [1/1] - Step [656/30732] - Loss: 0.00037498693563975394\n","Epoch [1/1] - Step [660/30732] - Loss: 0.0004264482413418591\n","Epoch [1/1] - Step [664/30732] - Loss: 0.0004308776988182217\n","Epoch [1/1] - Step [668/30732] - Loss: 0.0002949471236206591\n","Epoch [1/1] - Step [672/30732] - Loss: 0.0006110453978180885\n","Epoch [1/1] - Step [676/30732] - Loss: 0.0003844561579171568\n","Epoch [1/1] - Step [680/30732] - Loss: 0.016064226627349854\n","Epoch [1/1] - Step [684/30732] - Loss: 0.00042385284905321896\n","Epoch [1/1] - Step [688/30732] - Loss: 0.00040489056846126914\n","Epoch [1/1] - Step [692/30732] - Loss: 0.0006885457551106811\n","Epoch [1/1] - Step [696/30732] - Loss: 0.0004342592437751591\n","Epoch [1/1] - Step [700/30732] - Loss: 0.009912144392728806\n","Epoch [1/1] - Step [704/30732] - Loss: 0.0002962812432087958\n","Epoch [1/1] - Step [708/30732] - Loss: 0.004052817355841398\n","Epoch [1/1] - Step [712/30732] - Loss: 0.0002856674836948514\n","Epoch [1/1] - Step [716/30732] - Loss: 0.0003863229649141431\n","Epoch [1/1] - Step [720/30732] - Loss: 0.0005473652854561806\n","Epoch [1/1] - Step [724/30732] - Loss: 0.00033395696664229035\n","Epoch [1/1] - Step [728/30732] - Loss: 0.02046360820531845\n","Epoch [1/1] - Step [732/30732] - Loss: 0.08216838538646698\n","Epoch [1/1] - Step [736/30732] - Loss: 0.0003056580317206681\n","Epoch [1/1] - Step [740/30732] - Loss: 0.07393914461135864\n","Epoch [1/1] - Step [744/30732] - Loss: 0.00031861482420936227\n","Epoch [1/1] - Step [748/30732] - Loss: 0.00034760142443701625\n","Epoch [1/1] - Step [752/30732] - Loss: 0.0032950120512396097\n","Epoch [1/1] - Step [756/30732] - Loss: 0.00029559817630797625\n","Epoch [1/1] - Step [760/30732] - Loss: 0.00025528203696012497\n","Epoch [1/1] - Step [764/30732] - Loss: 0.0004323431639932096\n","Epoch [1/1] - Step [768/30732] - Loss: 0.018515877425670624\n","Epoch [1/1] - Step [772/30732] - Loss: 0.0005387358833104372\n","Epoch [1/1] - Step [776/30732] - Loss: 0.02577250450849533\n","Epoch [1/1] - Step [780/30732] - Loss: 0.0008315633749589324\n","Epoch [1/1] - Step [784/30732] - Loss: 0.00040777213871479034\n","Epoch [1/1] - Step [788/30732] - Loss: 0.0006008039927110076\n","Epoch [1/1] - Step [792/30732] - Loss: 0.0014027084689587355\n","Epoch [1/1] - Step [796/30732] - Loss: 0.004218306392431259\n","Epoch [1/1] - Step [800/30732] - Loss: 0.0004098176141269505\n","Epoch [1/1] - Step [804/30732] - Loss: 0.00029248720966279507\n","Epoch [1/1] - Step [808/30732] - Loss: 0.0003439446445554495\n","Epoch [1/1] - Step [812/30732] - Loss: 0.00029355473816394806\n","Epoch [1/1] - Step [816/30732] - Loss: 0.00028550345450639725\n","Epoch [1/1] - Step [820/30732] - Loss: 0.02443976327776909\n","Epoch [1/1] - Step [824/30732] - Loss: 0.000403695652494207\n","Epoch [1/1] - Step [828/30732] - Loss: 0.0002728356048464775\n","Epoch [1/1] - Step [832/30732] - Loss: 0.01721358858048916\n","Epoch [1/1] - Step [836/30732] - Loss: 0.0002567893243394792\n","Epoch [1/1] - Step [840/30732] - Loss: 0.00036671492853201926\n","Epoch [1/1] - Step [844/30732] - Loss: 0.0002621662279125303\n","Epoch [1/1] - Step [848/30732] - Loss: 0.002645558677613735\n","Epoch [1/1] - Step [852/30732] - Loss: 0.0002455527428537607\n","Epoch [1/1] - Step [856/30732] - Loss: 0.05225914716720581\n","Epoch [1/1] - Step [860/30732] - Loss: 0.00022271269699558616\n","Epoch [1/1] - Step [864/30732] - Loss: 0.0003593857982195914\n","Epoch [1/1] - Step [868/30732] - Loss: 0.00029726364300586283\n","Epoch [1/1] - Step [872/30732] - Loss: 0.00024483888410031796\n","Epoch [1/1] - Step [876/30732] - Loss: 0.016918767243623734\n","Epoch [1/1] - Step [880/30732] - Loss: 0.0005164036992937326\n","Epoch [1/1] - Step [884/30732] - Loss: 0.0013931792927905917\n","Epoch [1/1] - Step [888/30732] - Loss: 0.00019491009879857302\n","Epoch [1/1] - Step [892/30732] - Loss: 0.0008491540793329477\n","Epoch [1/1] - Step [896/30732] - Loss: 0.00022268397151492536\n","Epoch [1/1] - Step [900/30732] - Loss: 0.00017902374383993447\n","Epoch [1/1] - Step [904/30732] - Loss: 0.0001783310144674033\n","Epoch [1/1] - Step [908/30732] - Loss: 0.00022890939726494253\n","Epoch [1/1] - Step [912/30732] - Loss: 0.00017302361084148288\n","Epoch [1/1] - Step [916/30732] - Loss: 0.008253932930529118\n","Epoch [1/1] - Step [920/30732] - Loss: 0.08128438144922256\n","Epoch [1/1] - Step [924/30732] - Loss: 0.0002181738818762824\n","Epoch [1/1] - Step [928/30732] - Loss: 0.0002021696709562093\n","Epoch [1/1] - Step [932/30732] - Loss: 0.0011477743973955512\n","Epoch [1/1] - Step [936/30732] - Loss: 0.0006010278593748808\n","Epoch [1/1] - Step [940/30732] - Loss: 0.00018333192565478384\n","Epoch [1/1] - Step [944/30732] - Loss: 0.0001696794934105128\n","Epoch [1/1] - Step [948/30732] - Loss: 0.00065322604496032\n","Epoch [1/1] - Step [952/30732] - Loss: 0.0001906889956444502\n","Epoch [1/1] - Step [956/30732] - Loss: 0.0006124599603936076\n","Epoch [1/1] - Step [960/30732] - Loss: 0.003296359907835722\n","Epoch [1/1] - Step [964/30732] - Loss: 0.036868926137685776\n","Epoch [1/1] - Step [968/30732] - Loss: 0.00021813531930092722\n","Epoch [1/1] - Step [972/30732] - Loss: 0.00027055913233198225\n","Epoch [1/1] - Step [976/30732] - Loss: 0.002027621492743492\n","Epoch [1/1] - Step [980/30732] - Loss: 0.0005624404875561595\n","Epoch [1/1] - Step [984/30732] - Loss: 0.0012153397547081113\n","Epoch [1/1] - Step [988/30732] - Loss: 0.0002759259659796953\n","Epoch [1/1] - Step [992/30732] - Loss: 0.0002550558710936457\n","Epoch [1/1] - Step [996/30732] - Loss: 0.015882251784205437\n","Epoch [1/1] - Step [1000/30732] - Loss: 0.00021985723287798464\n","Epoch [1/1] - Step [1004/30732] - Loss: 0.00024835896329022944\n","Epoch [1/1] - Step [1008/30732] - Loss: 0.0002500355476513505\n","Epoch [1/1] - Step [1012/30732] - Loss: 0.00023524418065790087\n","Epoch [1/1] - Step [1016/30732] - Loss: 0.0002609743387438357\n","Epoch [1/1] - Step [1020/30732] - Loss: 0.00043793601798824966\n","Epoch [1/1] - Step [1024/30732] - Loss: 0.004893481265753508\n","Epoch [1/1] - Step [1028/30732] - Loss: 0.00028235086938366294\n","Epoch [1/1] - Step [1032/30732] - Loss: 0.0002469854080118239\n","Epoch [1/1] - Step [1036/30732] - Loss: 0.0002540721034165472\n","Epoch [1/1] - Step [1040/30732] - Loss: 0.0002745368401519954\n","Epoch [1/1] - Step [1044/30732] - Loss: 0.00024071449297480285\n","Epoch [1/1] - Step [1048/30732] - Loss: 0.00028262805426493287\n","Epoch [1/1] - Step [1052/30732] - Loss: 0.00023630590294487774\n","Epoch [1/1] - Step [1056/30732] - Loss: 0.0002822637907229364\n","Epoch [1/1] - Step [1060/30732] - Loss: 0.000222339469473809\n","Epoch [1/1] - Step [1064/30732] - Loss: 0.00021133395785000175\n","Epoch [1/1] - Step [1068/30732] - Loss: 0.00021391702466644347\n","Epoch [1/1] - Step [1072/30732] - Loss: 0.00020707478688564152\n","Epoch [1/1] - Step [1076/30732] - Loss: 0.00410937424749136\n","Epoch [1/1] - Step [1080/30732] - Loss: 0.00022733960940968245\n","Epoch [1/1] - Step [1084/30732] - Loss: 0.0002636127173900604\n","Epoch [1/1] - Step [1088/30732] - Loss: 0.0002052604395430535\n","Epoch [1/1] - Step [1092/30732] - Loss: 0.0001923054369399324\n","Epoch [1/1] - Step [1096/30732] - Loss: 0.00017449850565753877\n","Epoch [1/1] - Step [1100/30732] - Loss: 0.00039261661004275084\n","Epoch [1/1] - Step [1104/30732] - Loss: 0.00042564436444081366\n","Epoch [1/1] - Step [1108/30732] - Loss: 0.00031217350624501705\n","Epoch [1/1] - Step [1112/30732] - Loss: 0.00018783807172439992\n","Epoch [1/1] - Step [1116/30732] - Loss: 0.00019644846906885505\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-38-a0344372e8e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1346\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3012\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4086\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4087\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4088\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    877\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Convert any objects of type core_types.Tensor to Tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     inputs = [\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m     inputs = [\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m   \u001b[0moverload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__tf_tensor__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moverload\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(num_epochs):\n","    for batch in train_dataset_tf:\n","        input_ids, attention_mask, labels = batch\n","\n","        with tf.GradientTape() as tape:\n","            outputs = model(input_ids, attention_mask=attention_mask, training=True)\n","            logits = outputs.logits\n","            loss = loss_fn(labels, logits)\n","\n","            loss = loss / accumulation_steps  # Scale the loss\n","\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","        step += 1  # Increment the step counter\n","\n","        if step % accumulation_steps == 0:\n","            print(f\"Epoch [{epoch + 1}/{num_epochs}] - Step [{step}/{len(train_dataset_tf)}] - Loss: {loss.numpy()}\")"]},{"cell_type":"markdown","metadata":{"id":"Jad1Jqy_lGJT"},"source":["### Saving the model\n","We save the model using model.save in tf format which is suitable for tf serving."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koEoewAkriC5"},"outputs":[],"source":["model.save('T5_ext_summ')"]},{"cell_type":"code","source":["model.save(\"saved_model/1\", save_format=\"tf\")"],"metadata":{"id":"6fguQZeZ5_9z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7Xw2Jl0lGJU"},"source":["### Testing the model\n","* We take the baseline article and tokenize it. We preprocess it like before and send it the model.\n","* The output is taken and labels that have highest similarity are extracted.\n","* The sentence with high similarity is printed as summary."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzNuGkw13-jC","outputId":"c6ae676a-3e1e-4711-aa4a-f630db6cfb8d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Summary:\n","The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed\n"]}],"source":["article = \"The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed. Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water. Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct. Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town. First Minister Nicola Sturgeon visited the area to inspect the damage. The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare. Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\"\n","# Tokenizing the article\n","article_tokens = tokenizer(article, padding=\"max_length\", truncation=True, return_tensors=\"tf\", max_length=max_length)\n","input_ids = tf.convert_to_tensor(article_tokens[\"input_ids\"])\n","attention_mask = tf.convert_to_tensor(article_tokens[\"attention_mask\"])\n","\n","model_output = model(input_ids, attention_mask=attention_mask)\n","logits = model_output.logits\n","\n","generated_summary = \"\".join(article.split(\".\")[tf.argmax(logits, axis=1).numpy()[0]])\n","\n","print(\"Generated Summary:\")\n","print(generated_summary)"]},{"cell_type":"markdown","metadata":{"id":"LB5wZh0vlGJV"},"source":["### Model metrics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO5ODwE3lGJV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"56d63cfb-73dd-4d53-daf2-6ef03078c427"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install bert_score -q\n","from bert_score import score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DiwVCdzVlGJW"},"outputs":[],"source":["gen_summary=[generated_summary]\n","text=[article]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGOuAghplGJW","outputId":"87bac920-5637-4a72-a6c2-47296791c2ab","colab":{"base_uri":"https://localhost:8080/","height":232,"referenced_widgets":["12ef250844ca4f0f8f93ac5c1e8296d2","d032ec0c6ccc4e7a9418ae761eda3af8","688728a2f3c04f4bb7ab56252a5d9c6d","16cd7d7ef33b44c6842a33401b8fa15c","f9a4a373e8e04f7faee890cdb0fcd78e","8fbfc1691da5461c8fc643d2c1078b04","297adc6f9477452aa0c2d23b3792e4db","ada7b8fb17e54264ab65ffc017a8e7a7","00374f0f1dc34864bf6bd309d1ebf3f8","42cced75ed9e473baca5a49dd446b6f3","ac5925a9dea346aca0270d3805b69adb","95ca94431f804bfbab0783c0315baf06","276343919231428488cdcc7184088d3c","796b7efcaf7e43ad94228ace2c3f39c5","12a7bf20e70e42aba23edd42ac421013","d5e28645f9f240549a07dc7dc1ae31fe","749eed1dfee34de5b7ef848ddaa443d0","ee010322f72a44b791688b04c2371cb7","28f5db5ad2a64df9bdbd8cf50cf19275","1582823a8bca489ab76615074d9b7598","c0a305b024404c7da7662a7a066f4af1","a71d0315aa2f4a08b58f720016309226","64a3cac97e934986b47d079d7e2cf79b","e07fe91abc864ed490c6832a24506418","ac53bc11c8214a43a5299b2f53fde1a5","4b470f7af135495fb3da9cd2cfdd0a0e","4ba57eed593c419f9eea5e38353bdd7c","1a8f290a720147d1a309ef28a720d8dd","216d2c8ffa4d46a8b4bf1f86bd98fb26","1d52bb3625234677b96f744442445c96","7e5ec8b36487424b88edfb8d3f93ea95","8a078a9a15ba4cc1b463ab40742281a1","45ebd10a723246309a6fdad1fce836db","9b12f2c671dd49f6818e312f51fed632","c5ffce5bc7a8478dbf8077f0816fa526","727df66eed3b432ebab831165f8cf7bb","64a9e38e36974796975d04856e034b41","6a2a00b2691342aeac75a9689d20c73f","b290c5a099164898a64e9a5e208bd314","6e42bf8e71f5489d987659aa42314003","cc90d6ee1fd941a1879f7e411aa594fc","25be248db4584e20a3a03e957f46e734","b2ac9b699a974f65bce86435754aecf9","0490ebec284b4f58bc42e58989f055d2","c6c4795e858a48db9634487c8f73a182","7bb3ce70ea9a44b9b85dea463ccd118e","9b576ba533e148e5b114032dce75c94f","62f050feca1c441c8f2732f1776372f2","2a413b6d280f442887c88e551968ab1f","bf1a09f4f31c41bca84b68aca4dd3634","2220301206d14a0cb504bacb65979f36","068e454d09164bc49d9daa8bfd14f0c5","fcad9abd8709480b9019dcd73fec1f94","1f722dd68f5846ab8feec0dc659a8301","13a6aa4575cb476bbe91626faa910f99"]}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12ef250844ca4f0f8f93ac5c1e8296d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ca94431f804bfbab0783c0315baf06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64a3cac97e934986b47d079d7e2cf79b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b12f2c671dd49f6818e312f51fed632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c4795e858a48db9634487c8f73a182"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["P,R,F1=score(gen_summary,text,lang='en')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPeyG1QClGJX","outputId":"0dda4f5e-4213-4f38-8d74-fc3cbf64c3f1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Pair1\n","Precision(P): 0.9601625800132751\n","Recall(R): 0.8428446054458618\n","F1 Score: 0.8976868391036987\n","\n","\n"]}],"source":["for i in range(len(gen_summary)):\n","    print(f\"Pair{i+1}\")\n","    print(f\"Precision(P): {P[i].item()}\")\n","    print(f\"Recall(R): {R[i].item()}\")\n","    print(f\"F1 Score: {F1[i].item()}\")\n","    print()\n","    print()"]},{"cell_type":"markdown","source":["### Downloading the saved_model"],"metadata":{"id":"0psAi5io4Yao"}},{"cell_type":"code","source":["!zip -r ext_summ.zip /content/saved_model\n","from google.colab import files\n","files.download(\"ext_summ.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"DNFA_v-e5dNy","outputId":"74de03c5-3850-481d-d2d5-3f6f65bb9d18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/saved_model/ (stored 0%)\n","  adding: content/saved_model/1/ (stored 0%)\n","  adding: content/saved_model/1/assets/ (stored 0%)\n","  adding: content/saved_model/1/keras_metadata.pb (deflated 96%)\n","  adding: content/saved_model/1/fingerprint.pb (stored 0%)\n","  adding: content/saved_model/1/saved_model.pb (deflated 92%)\n","  adding: content/saved_model/1/variables/ (stored 0%)\n","  adding: content/saved_model/1/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: content/saved_model/1/variables/variables.index (deflated 77%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_48bd2a70-02f3-4928-ab2a-ef66d4688504\", \"ext_summ.zip\", 405766942)"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Serving the Summarizer"],"metadata":{"id":"D1LxNOh-2T_w"}},{"cell_type":"markdown","source":["### Saving the model and exploring the saved_model"],"metadata":{"id":"B0gWCLoq3KG3"}},{"cell_type":"code","source":["export_path='/content/saved_model/1'\n","!saved_model_cli show --dir {export_path} --all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rsP0OoG7V5z","outputId":"f19bca13-407f-45fd-a13e-8107b68e9bfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-07 17:56:53.838306: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-07 17:56:53.838368: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-07 17:56:53.838401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-07 17:56:56.892040: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\n","MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n","\n","signature_def['__saved_model_init_op']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['__saved_model_init_op'] tensor_info:\n","        dtype: DT_INVALID\n","        shape: unknown_rank\n","        name: NoOp\n","  Method name is: \n","\n","signature_def['serving_default']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","    inputs['attention_mask'] tensor_info:\n","        dtype: DT_INT32\n","        shape: (-1, -1)\n","        name: serving_default_attention_mask:0\n","    inputs['input_ids'] tensor_info:\n","        dtype: DT_INT32\n","        shape: (-1, -1)\n","        name: serving_default_input_ids:0\n","    inputs['token_type_ids'] tensor_info:\n","        dtype: DT_INT32\n","        shape: (-1, -1)\n","        name: serving_default_token_type_ids:0\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['logits'] tensor_info:\n","        dtype: DT_FLOAT\n","        shape: (-1, 2)\n","        name: StatefulPartitionedCall:0\n","  Method name is: tensorflow/serving/predict\n","The MetaGraph with tag set ['serve'] contains the following ops: {'AddV2', 'Range', 'Rsqrt', 'MatMul', 'StopGradient', 'MergeV2Checkpoints', 'NoOp', 'RealDiv', 'DisableCopyOnRead', 'AssignVariableOp', 'StringJoin', 'Shape', 'Select', 'ConcatV2', 'BatchMatMulV2', 'ShardedFilename', 'Const', 'Pack', 'Transpose', 'All', 'Placeholder', 'SaveV2', 'Prod', 'Softmax', 'GatherV2', 'Mul', 'Max', 'StridedSlice', 'Reshape', 'ReadVariableOp', 'BiasAdd', 'StaticRegexFullMatch', 'Mean', 'Erf', 'SquaredDifference', 'RestoreV2', 'ExpandDims', 'Identity', 'StatefulPartitionedCall', 'Less', 'ResourceGather', 'VarHandleOp', 'Cast', 'Sub', 'Assert', 'Tanh'}\n","2023-11-07 17:57:03.277791: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","\n","Concrete Functions:\n","  Function Name: '__call__'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          DType: dict\n","          Value: {'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids'), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='token_type_ids'), \b\b}\n","        Argument #2\n","          DType: NoneType\n","          Value: None\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","        Argument #4\n","          DType: NoneType\n","          Value: None\n","        Argument #5\n","          DType: NoneType\n","          Value: None\n","        Argument #6\n","          DType: NoneType\n","          Value: None\n","        Argument #7\n","          DType: NoneType\n","          Value: None\n","        Argument #8\n","          DType: NoneType\n","          Value: None\n","        Argument #9\n","          DType: NoneType\n","          Value: None\n","        Argument #10\n","          DType: NoneType\n","          Value: None\n","        Argument #11\n","          DType: bool\n","          Value: True\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          DType: dict\n","          Value: {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='token_type_ids'), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids'), \b\b}\n","        Argument #2\n","          DType: NoneType\n","          Value: None\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","        Argument #4\n","          DType: NoneType\n","          Value: None\n","        Argument #5\n","          DType: NoneType\n","          Value: None\n","        Argument #6\n","          DType: NoneType\n","          Value: None\n","        Argument #7\n","          DType: NoneType\n","          Value: None\n","        Argument #8\n","          DType: NoneType\n","          Value: None\n","        Argument #9\n","          DType: NoneType\n","          Value: None\n","        Argument #10\n","          DType: NoneType\n","          Value: None\n","        Argument #11\n","          DType: bool\n","          Value: False\n","\n","  Function Name: '_default_save_signature'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          DType: dict\n","          Value: {'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids'), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='token_type_ids'), \b\b}\n","\n","  Function Name: 'call_and_return_all_conditional_losses'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          DType: dict\n","          Value: {'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids'), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='token_type_ids'), \b\b}\n","        Argument #2\n","          DType: NoneType\n","          Value: None\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","        Argument #4\n","          DType: NoneType\n","          Value: None\n","        Argument #5\n","          DType: NoneType\n","          Value: None\n","        Argument #6\n","          DType: NoneType\n","          Value: None\n","        Argument #7\n","          DType: NoneType\n","          Value: None\n","        Argument #8\n","          DType: NoneType\n","          Value: None\n","        Argument #9\n","          DType: NoneType\n","          Value: None\n","        Argument #10\n","          DType: NoneType\n","          Value: None\n","        Argument #11\n","          DType: bool\n","          Value: True\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          DType: dict\n","          Value: {'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_ids_input_ids'), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='token_type_ids'), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='attention_mask'), \b\b}\n","        Argument #2\n","          DType: NoneType\n","          Value: None\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","        Argument #4\n","          DType: NoneType\n","          Value: None\n","        Argument #5\n","          DType: NoneType\n","          Value: None\n","        Argument #6\n","          DType: NoneType\n","          Value: None\n","        Argument #7\n","          DType: NoneType\n","          Value: None\n","        Argument #8\n","          DType: NoneType\n","          Value: None\n","        Argument #9\n","          DType: NoneType\n","          Value: None\n","        Argument #10\n","          DType: NoneType\n","          Value: None\n","        Argument #11\n","          DType: bool\n","          Value: False\n","\n","  Function Name: 'serving'\n"]}]},{"cell_type":"markdown","source":["### Installing TF serving"],"metadata":{"id":"5vYgaf7X3QAY"}},{"cell_type":"code","source":["!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n","curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n","!apt update"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEpr9NFw7-lB","outputId":"4fdc0108-6c4e-40b8-a6e4-a982d34b4d5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n","100  2943  100  2943    0     0   3429      0 --:--:-- --:--:-- --:--:--  3426\n","OK\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [46.6 kB]\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,240 kB]\n","Get:12 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,150 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:14 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,008 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,192 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,419 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,461 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n","Get:21 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [348 B]\n","Get:22 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n","Fetched 10.2 MB in 2s (4,091 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","43 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mhttp://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n"]}]},{"cell_type":"code","source":["!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-2.8.0/t/tensorflow-model-server/tensorflow-model-server_2.8.0_all.deb'\n","!dpkg -i tensorflow-model-server_2.8.0_all.deb\n","!pip3 install tensorflow-serving-api==2.8.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pn6Y77A_7-gX","outputId":"4fe088b2-97ec-44cd-8684-6693be4c6a83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-07 18:04:26--  http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-2.8.0/t/tensorflow-model-server/tensorflow-model-server_2.8.0_all.deb\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 74.125.128.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 340152790 (324M) [application/x-debian-package]\n","Saving to: ‘tensorflow-model-server_2.8.0_all.deb’\n","\n","tensorflow-model-se 100%[===================>] 324.39M  28.6MB/s    in 11s     \n","\n","2023-11-07 18:04:38 (28.3 MB/s) - ‘tensorflow-model-server_2.8.0_all.deb’ saved [340152790/340152790]\n","\n","Selecting previously unselected package tensorflow-model-server.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack tensorflow-model-server_2.8.0_all.deb ...\n","Unpacking tensorflow-model-server (2.8.0) ...\n","Setting up tensorflow-model-server (2.8.0) ...\n","Collecting tensorflow-serving-api==2.8.0\n","  Downloading tensorflow_serving_api-2.8.0-py2.py3-none-any.whl (37 kB)\n","Requirement already satisfied: grpcio<2,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api==2.8.0) (1.59.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api==2.8.0) (3.20.3)\n","Requirement already satisfied: tensorflow<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api==2.8.0) (2.14.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.2.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.34.0)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.2.2)\n","Installing collected packages: tensorflow-serving-api\n","Successfully installed tensorflow-serving-api-2.8.0\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"MODEL_DIR\"] = MODEL_DIR"],"metadata":{"id":"G91xhpiv-LDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Cc7EO4wM8NkK","outputId":"8295de0d-6b72-4bf4-a03e-13bb0846af49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/saved_model'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":61}]},{"cell_type":"markdown","source":["### Starting TF Model server"],"metadata":{"id":"x8nS-V0-3Tfa"}},{"cell_type":"code","source":["%%bash --bg\n","nohup tensorflow_model_server \\\n","  --rest_api_port=8501 \\\n","  --model_name=ext_model \\\n","  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"],"metadata":{"id":"x9VH75qt7-bh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tail server.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wValDkf7-UP","outputId":"23588d0f-761e-44f9-eb11-f62f4fc74b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-07 18:09:19.858959: E external/org_tensorflow/tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: NOT_FOUND: Op type not registered 'DisableCopyOnRead' in binary running on e2871df5ca98. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n","\twhen importing GraphDef to MLIR module in GrapplerHook\n","2023-11-07 18:09:20.763275: W external/org_tensorflow/tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"]}]},{"cell_type":"code","source":["!ps aux | grep tensorflow_model_server"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eu-COZ7-ixj","outputId":"67d872ad-fae0-4be3-a6d8-2acc63d9c0e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root       24431  4.6  5.1 2023996 688984 ?      Sl   18:09   0:02 tensorflow_model_server --rest_ap\n","root       24675  0.0  0.0   6616  2392 ?        S    18:10   0:00 grep tensorflow_model_server\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","import numpy as np"],"metadata":{"id":"I5j_53oq7-H6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metadata_url = \"http://localhost:8501/v1/models/ext_model/metadata\"\n","\n","# Send a request to get the model metadata\n","response = requests.get(metadata_url)\n","\n","# Parse the JSON response\n","metadata = response.json()\n","\n","# Print the signature information\n","print(metadata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sELX4g-m-ps6","outputId":"20993264-a4f0-47e5-bb1b-86e203b831ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'model_spec': {'name': 'ext_model', 'signature_name': '', 'version': '1'}, 'metadata': {'signature_def': {'signature_def': {'serving_default': {'inputs': {'token_type_ids': {'dtype': 'DT_INT32', 'tensor_shape': {'dim': [{'size': '-1', 'name': ''}, {'size': '-1', 'name': ''}], 'unknown_rank': False}, 'name': 'serving_default_token_type_ids:0'}, 'attention_mask': {'dtype': 'DT_INT32', 'tensor_shape': {'dim': [{'size': '-1', 'name': ''}, {'size': '-1', 'name': ''}], 'unknown_rank': False}, 'name': 'serving_default_attention_mask:0'}, 'input_ids': {'dtype': 'DT_INT32', 'tensor_shape': {'dim': [{'size': '-1', 'name': ''}, {'size': '-1', 'name': ''}], 'unknown_rank': False}, 'name': 'serving_default_input_ids:0'}}, 'outputs': {'logits': {'dtype': 'DT_FLOAT', 'tensor_shape': {'dim': [{'size': '-1', 'name': ''}, {'size': '2', 'name': ''}], 'unknown_rank': False}, 'name': 'StatefulPartitionedCall:0'}}, 'method_name': 'tensorflow/serving/predict'}, '__saved_model_init_op': {'inputs': {}, 'outputs': {'__saved_model_init_op': {'dtype': 'DT_INVALID', 'tensor_shape': {'dim': [], 'unknown_rank': True}, 'name': 'NoOp'}}, 'method_name': ''}}}}}\n"]}]},{"cell_type":"markdown","source":["### Generating summary using TF serving\n","* We take the baseline article and pre-process it using the bert tokenizer.\n","* The data is then convered into a format suitable to sent to the serving.\n","* We define the rest_api url at which the model is served and its format.\n","* The data is changed to json format and rest api request is sent.\n","* After the model generates summary, it is read and decoded into human readable format."],"metadata":{"id":"i2v3h1IH3mss"}},{"cell_type":"code","source":["article_serving = \"The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed. Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water. Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct. Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town. First Minister Nicola Sturgeon visited the area to inspect the damage. The waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare. Jeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\""],"metadata":{"id":"K2fOryT68pBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_serv = tokenizer(article_serving, padding=\"max_length\", truncation=True, return_tensors=\"tf\", max_length=256)"],"metadata":{"id":"PYrFAd-j8o-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_data = {\n","    'input_ids': tokenized_serv['input_ids'].numpy().tolist(),\n","    'attention_mask': tokenized_serv['attention_mask'].numpy().tolist()\n","}\n","\n","#Define the input data for TensorFlow Serving\n","data = {\n","    'signature_name': 'serving_default',\n","    'instances': [input_data]\n","}"],"metadata":{"id":"_-2DrfRS8u_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["server_url = \"http://localhost:8501/v1/models/ext_model:predict\"\n","headers = {\"content-type\": \"application/json\"}\n","response = requests.post(server_url, data=json.dumps(data), headers = headers)"],"metadata":{"id":"KoTi0pFb8u8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = json.loads(response.text)\n","#print(result)\n","pred_tokens = result[0]['output_0']\n","generated_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n","print(\"Generated Summary: \")\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19phoUbW81Si","outputId":"90986ee0-8bb5-485a-e98f-9b4d87cce0f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Summary:\n","The full cost of damages in Newton Stewart, one of the areas worst affected, is still being assessed\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["iO97VXXtriJl","8crO3WALrp2u","V4Jw97rBlGI6","CV25YO8dlGJE","neK9TzcLlGJK","FxaQiGL2lGJM","CxADq8c6lGJO","c3TitSiAlGJP","Rp4G6wjLlGJQ","C-u9HWtKlGJS","Jad1Jqy_lGJT","n7Xw2Jl0lGJU","LB5wZh0vlGJV","0psAi5io4Yao","D1LxNOh-2T_w","B0gWCLoq3KG3","5vYgaf7X3QAY","x8nS-V0-3Tfa","i2v3h1IH3mss"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d2a46f7007494eb88cc01eeebfc6d683":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a08dffc17cf54132b4e2c5fcab05b7f9","IPY_MODEL_5d2e7a414dcd4e29b563f15d4fc8312e","IPY_MODEL_a25399bd0c4849d7aabb4411cf21569e"],"layout":"IPY_MODEL_3a152bf1916b4baaa9571646025744e6"}},"a08dffc17cf54132b4e2c5fcab05b7f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09f4cfcc5df48e8b2884b888c1cf6e3","placeholder":"​","style":"IPY_MODEL_5e1ba5f11fa24dbd8271d851564374da","value":"Downloading model.safetensors: 100%"}},"5d2e7a414dcd4e29b563f15d4fc8312e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_444877b0dfc74a2d99c1fd385080bc93","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e849f91bdc424fa8ab21de66e6f30778","value":440449768}},"a25399bd0c4849d7aabb4411cf21569e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9186d11502448aabb12eaabab99445b","placeholder":"​","style":"IPY_MODEL_d38313cb1cb04dacbc7d1330bb0d4fe3","value":" 440M/440M [00:06&lt;00:00, 78.7MB/s]"}},"3a152bf1916b4baaa9571646025744e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b09f4cfcc5df48e8b2884b888c1cf6e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e1ba5f11fa24dbd8271d851564374da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"444877b0dfc74a2d99c1fd385080bc93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e849f91bdc424fa8ab21de66e6f30778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9186d11502448aabb12eaabab99445b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d38313cb1cb04dacbc7d1330bb0d4fe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12ef250844ca4f0f8f93ac5c1e8296d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d032ec0c6ccc4e7a9418ae761eda3af8","IPY_MODEL_688728a2f3c04f4bb7ab56252a5d9c6d","IPY_MODEL_16cd7d7ef33b44c6842a33401b8fa15c"],"layout":"IPY_MODEL_f9a4a373e8e04f7faee890cdb0fcd78e"}},"d032ec0c6ccc4e7a9418ae761eda3af8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fbfc1691da5461c8fc643d2c1078b04","placeholder":"​","style":"IPY_MODEL_297adc6f9477452aa0c2d23b3792e4db","value":"Downloading (…)lve/main/config.json: 100%"}},"688728a2f3c04f4bb7ab56252a5d9c6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ada7b8fb17e54264ab65ffc017a8e7a7","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00374f0f1dc34864bf6bd309d1ebf3f8","value":482}},"16cd7d7ef33b44c6842a33401b8fa15c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42cced75ed9e473baca5a49dd446b6f3","placeholder":"​","style":"IPY_MODEL_ac5925a9dea346aca0270d3805b69adb","value":" 482/482 [00:00&lt;00:00, 30.1kB/s]"}},"f9a4a373e8e04f7faee890cdb0fcd78e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fbfc1691da5461c8fc643d2c1078b04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"297adc6f9477452aa0c2d23b3792e4db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ada7b8fb17e54264ab65ffc017a8e7a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00374f0f1dc34864bf6bd309d1ebf3f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42cced75ed9e473baca5a49dd446b6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac5925a9dea346aca0270d3805b69adb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95ca94431f804bfbab0783c0315baf06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_276343919231428488cdcc7184088d3c","IPY_MODEL_796b7efcaf7e43ad94228ace2c3f39c5","IPY_MODEL_12a7bf20e70e42aba23edd42ac421013"],"layout":"IPY_MODEL_d5e28645f9f240549a07dc7dc1ae31fe"}},"276343919231428488cdcc7184088d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_749eed1dfee34de5b7ef848ddaa443d0","placeholder":"​","style":"IPY_MODEL_ee010322f72a44b791688b04c2371cb7","value":"Downloading (…)olve/main/vocab.json: 100%"}},"796b7efcaf7e43ad94228ace2c3f39c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28f5db5ad2a64df9bdbd8cf50cf19275","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1582823a8bca489ab76615074d9b7598","value":898823}},"12a7bf20e70e42aba23edd42ac421013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0a305b024404c7da7662a7a066f4af1","placeholder":"​","style":"IPY_MODEL_a71d0315aa2f4a08b58f720016309226","value":" 899k/899k [00:00&lt;00:00, 5.37MB/s]"}},"d5e28645f9f240549a07dc7dc1ae31fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"749eed1dfee34de5b7ef848ddaa443d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee010322f72a44b791688b04c2371cb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28f5db5ad2a64df9bdbd8cf50cf19275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1582823a8bca489ab76615074d9b7598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0a305b024404c7da7662a7a066f4af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a71d0315aa2f4a08b58f720016309226":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64a3cac97e934986b47d079d7e2cf79b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e07fe91abc864ed490c6832a24506418","IPY_MODEL_ac53bc11c8214a43a5299b2f53fde1a5","IPY_MODEL_4b470f7af135495fb3da9cd2cfdd0a0e"],"layout":"IPY_MODEL_4ba57eed593c419f9eea5e38353bdd7c"}},"e07fe91abc864ed490c6832a24506418":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a8f290a720147d1a309ef28a720d8dd","placeholder":"​","style":"IPY_MODEL_216d2c8ffa4d46a8b4bf1f86bd98fb26","value":"Downloading (…)olve/main/merges.txt: 100%"}},"ac53bc11c8214a43a5299b2f53fde1a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d52bb3625234677b96f744442445c96","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e5ec8b36487424b88edfb8d3f93ea95","value":456318}},"4b470f7af135495fb3da9cd2cfdd0a0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a078a9a15ba4cc1b463ab40742281a1","placeholder":"​","style":"IPY_MODEL_45ebd10a723246309a6fdad1fce836db","value":" 456k/456k [00:00&lt;00:00, 24.4MB/s]"}},"4ba57eed593c419f9eea5e38353bdd7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8f290a720147d1a309ef28a720d8dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"216d2c8ffa4d46a8b4bf1f86bd98fb26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d52bb3625234677b96f744442445c96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5ec8b36487424b88edfb8d3f93ea95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a078a9a15ba4cc1b463ab40742281a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45ebd10a723246309a6fdad1fce836db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b12f2c671dd49f6818e312f51fed632":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5ffce5bc7a8478dbf8077f0816fa526","IPY_MODEL_727df66eed3b432ebab831165f8cf7bb","IPY_MODEL_64a9e38e36974796975d04856e034b41"],"layout":"IPY_MODEL_6a2a00b2691342aeac75a9689d20c73f"}},"c5ffce5bc7a8478dbf8077f0816fa526":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b290c5a099164898a64e9a5e208bd314","placeholder":"​","style":"IPY_MODEL_6e42bf8e71f5489d987659aa42314003","value":"Downloading (…)/main/tokenizer.json: 100%"}},"727df66eed3b432ebab831165f8cf7bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc90d6ee1fd941a1879f7e411aa594fc","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25be248db4584e20a3a03e957f46e734","value":1355863}},"64a9e38e36974796975d04856e034b41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2ac9b699a974f65bce86435754aecf9","placeholder":"​","style":"IPY_MODEL_0490ebec284b4f58bc42e58989f055d2","value":" 1.36M/1.36M [00:00&lt;00:00, 5.48MB/s]"}},"6a2a00b2691342aeac75a9689d20c73f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b290c5a099164898a64e9a5e208bd314":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e42bf8e71f5489d987659aa42314003":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc90d6ee1fd941a1879f7e411aa594fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25be248db4584e20a3a03e957f46e734":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2ac9b699a974f65bce86435754aecf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0490ebec284b4f58bc42e58989f055d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6c4795e858a48db9634487c8f73a182":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bb3ce70ea9a44b9b85dea463ccd118e","IPY_MODEL_9b576ba533e148e5b114032dce75c94f","IPY_MODEL_62f050feca1c441c8f2732f1776372f2"],"layout":"IPY_MODEL_2a413b6d280f442887c88e551968ab1f"}},"7bb3ce70ea9a44b9b85dea463ccd118e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf1a09f4f31c41bca84b68aca4dd3634","placeholder":"​","style":"IPY_MODEL_2220301206d14a0cb504bacb65979f36","value":"Downloading model.safetensors: 100%"}},"9b576ba533e148e5b114032dce75c94f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_068e454d09164bc49d9daa8bfd14f0c5","max":1421700479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fcad9abd8709480b9019dcd73fec1f94","value":1421700479}},"62f050feca1c441c8f2732f1776372f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f722dd68f5846ab8feec0dc659a8301","placeholder":"​","style":"IPY_MODEL_13a6aa4575cb476bbe91626faa910f99","value":" 1.42G/1.42G [00:14&lt;00:00, 163MB/s]"}},"2a413b6d280f442887c88e551968ab1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf1a09f4f31c41bca84b68aca4dd3634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2220301206d14a0cb504bacb65979f36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"068e454d09164bc49d9daa8bfd14f0c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcad9abd8709480b9019dcd73fec1f94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f722dd68f5846ab8feec0dc659a8301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a6aa4575cb476bbe91626faa910f99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}